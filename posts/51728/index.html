<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0"><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous"><script class="next-config" data-name="main" type="application/json">{"hostname":"kycool.cn","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.21.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":true,"nav":null,"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"æœç´¢...","empty":"æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœç´¢ç»“æœï¼š${query}","hits_time":"æ‰¾åˆ° ${hits} ä¸ªæœç´¢ç»“æœï¼ˆç”¨æ—¶ ${time} æ¯«ç§’ï¼‰","hits":"æ‰¾åˆ° ${hits} ä¸ªæœç´¢ç»“æœ"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><meta name="description" content="ç®€å•æ¢³ç†ä¸‹ä½¿ç”¨ vllm é€šè¿‡ CPU æ¨¡å¼ï¼Œéƒ¨ç½²è¿è¡Œ Qwen&#x2F;Qwen2.5-1.5B-Instruct"><meta property="og:type" content="blog"><meta property="og:title" content="å¤§æ¨¡å‹ | CPU æ¨¡å¼éƒ¨ç½²è¿è¡Œ Qwen 2.5 å¤§æ¨¡å‹"><meta property="og:url" content="https://kycool.cn/posts/51728/index.html"><meta property="og:site_name" content="é’é˜³åŠé›ª"><meta property="og:description" content="ç®€å•æ¢³ç†ä¸‹ä½¿ç”¨ vllm é€šè¿‡ CPU æ¨¡å¼ï¼Œéƒ¨ç½²è¿è¡Œ Qwen&#x2F;Qwen2.5-1.5B-Instruct"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://kycool.cn/posts/51728/cpu-status.png"><meta property="og:image" content="https://kycool.cn/posts/51728/webui.png"><meta property="article:published_time" content="2024-10-31T06:03:49.000Z"><meta property="article:modified_time" content="2025-02-17T06:29:32.789Z"><meta property="article:author" content="é’é˜³åŠé›ª"><meta property="article:tag" content="å¤§æ¨¡å‹"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://kycool.cn/posts/51728/cpu-status.png"><link rel="canonical" href="https://kycool.cn/posts/51728/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://kycool.cn/posts/51728/","path":"posts/51728/","title":"å¤§æ¨¡å‹ | CPU æ¨¡å¼éƒ¨ç½²è¿è¡Œ Qwen 2.5 å¤§æ¨¡å‹"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>å¤§æ¨¡å‹ | CPU æ¨¡å¼éƒ¨ç½²è¿è¡Œ Qwen 2.5 å¤§æ¨¡å‹ | é’é˜³åŠé›ª</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="åˆ‡æ¢å¯¼èˆªæ " role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">é’é˜³åŠé›ª</p><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">ä¸ºå­¦æ—¥ç›ŠÂ·ä¸ºé“æ—¥æŸ</p></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="æœç´¢" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>é¦–é¡µ</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>å…³äº</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>æ ‡ç­¾<span class="badge">17</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>åˆ†ç±»<span class="badge">10</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>å½’æ¡£<span class="badge">20</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>æœç´¢</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="æœç´¢..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">æ–‡ç« ç›®å½•</li><li class="sidebar-nav-overview">ç«™ç‚¹æ¦‚è§ˆ</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-text">1 ç¯å¢ƒå‡†å¤‡</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F"><span class="nav-text">1.1 æ“ä½œç³»ç»Ÿ</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-conda-%E5%AE%89%E8%A3%85"><span class="nav-text">1.2 conda å®‰è£…</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-conda-%E9%95%9C%E5%83%8F%E8%AE%BE%E7%BD%AE"><span class="nav-text">1.3 conda é•œåƒè®¾ç½®</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-4-%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83"><span class="nav-text">1.4 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-5-%E5%AE%89%E8%A3%85-vllm"><span class="nav-text">1.5 å®‰è£… vllm</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD"><span class="nav-text">2 å¤§æ¨¡å‹ä¸‹è½½</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%8E%A8%E7%90%86-%E7%A6%BB%E7%BA%BF%E6%8E%A8%E7%90%86"><span class="nav-text">3 æ¨ç† - ç¦»çº¿æ¨ç†</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E6%8E%A8%E7%90%86-%E9%80%9A%E8%BF%87%E8%B0%83%E7%94%A8-api"><span class="nav-text">4 æ¨ç† - é€šè¿‡è°ƒç”¨ api</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-%E9%83%A8%E7%BD%B2%E5%A4%A7%E6%A8%A1%E5%9E%8B-api-%E6%9C%8D%E5%8A%A1"><span class="nav-text">4.1 éƒ¨ç½²å¤§æ¨¡å‹ api æœåŠ¡</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#4-1-1-%E9%83%A8%E7%BD%B2-api"><span class="nav-text">4.1.1 éƒ¨ç½² api</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-1-2-%E6%9F%A5%E7%9C%8B%E6%8E%A5%E5%8F%A3%E8%B7%AF%E7%94%B1"><span class="nav-text">4.1.2 æŸ¥çœ‹æ¥å£è·¯ç”±</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-%E8%84%9A%E6%9C%AC%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%B0%83%E7%94%A8-api"><span class="nav-text">4.2 è„šæœ¬å®¢æˆ·ç«¯è°ƒç”¨ api</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-%E9%80%9A%E8%BF%87-WebUI-%E8%B0%83%E7%94%A8-api"><span class="nav-text">4.3 é€šè¿‡ WebUI è°ƒç”¨ api</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-text">5 å‚è€ƒèµ„æ–™</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="é’é˜³åŠé›ª" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">é’é˜³åŠé›ª</p><div class="site-description" itemprop="description">ç‹¬æ­¥å¤©ä¸‹Â·æ— ä¸ä¸ºå¶</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">20</span> <span class="site-state-item-name">æ—¥å¿—</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">åˆ†ç±»</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">17</span> <span class="site-state-item-name">æ ‡ç­¾</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/kycool" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;kycool" rel="noopener me external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i></a> </span><span class="links-of-author-item"><a href="mailto:kycoolcool@gmail.com" title="E-Mail â†’ mailto:kycoolcool@gmail.com" rel="noopener me external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i></a></span></div><div class="cc-license animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener external nofollow noreferrer" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div><div class="back-to-top animated" role="button" aria-label="è¿”å›é¡¶éƒ¨"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div><div class="pjax"></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://kycool.cn/posts/51728/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="é’é˜³åŠé›ª"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="é’é˜³åŠé›ª"><meta itemprop="description" content="ç‹¬æ­¥å¤©ä¸‹Â·æ— ä¸ä¸ºå¶"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="å¤§æ¨¡å‹ | CPU æ¨¡å¼éƒ¨ç½²è¿è¡Œ Qwen 2.5 å¤§æ¨¡å‹ | é’é˜³åŠé›ª"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">å¤§æ¨¡å‹ | CPU æ¨¡å¼éƒ¨ç½²è¿è¡Œ Qwen 2.5 å¤§æ¨¡å‹</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">å‘è¡¨äº</span> <time title="åˆ›å»ºæ—¶é—´ï¼š2024-10-31 14:03:49" itemprop="dateCreated datePublished" datetime="2024-10-31T14:03:49+08:00">2024-10-31</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">æ›´æ–°äº</span> <time title="ä¿®æ”¹æ—¶é—´ï¼š2025-02-17 14:29:32" itemprop="dateModified" datetime="2025-02-17T14:29:32+08:00">2025-02-17</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">åˆ†ç±»äº</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">äººå·¥æ™ºèƒ½</span></a> </span></span><span class="post-meta-item" title="é˜…è¯»æ¬¡æ•°" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span> <span id="busuanzi_value_page_pv"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span> <span>33k</span> </span><span class="post-meta-item" title="é˜…è¯»æ—¶é•¿"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span> <span>30 åˆ†é’Ÿ</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>ç®€å•æ¢³ç†ä¸‹ä½¿ç”¨ vllm é€šè¿‡ CPU æ¨¡å¼ï¼Œéƒ¨ç½²è¿è¡Œ Qwen&#x2F;Qwen2.5-1.5B-Instruct<span id="more"></span></p><h3 id="1-ç¯å¢ƒå‡†å¤‡"><a href="#1-ç¯å¢ƒå‡†å¤‡" class="headerlink" title="1 ç¯å¢ƒå‡†å¤‡"></a>1 ç¯å¢ƒå‡†å¤‡</h3><h4 id="1-1-æ“ä½œç³»ç»Ÿ"><a href="#1-1-æ“ä½œç³»ç»Ÿ" class="headerlink" title="1.1 æ“ä½œç³»ç»Ÿ"></a>1.1 æ“ä½œç³»ç»Ÿ</h4><p>ä½¿ç”¨çš„æ˜¯ <code>Ubuntu</code> ç‰ˆæœ¬å·ï¼š<code>24.04.1 LTS</code>ï¼Œ32 G å†…å­˜ï¼Œ16 æ ¸çš„ CPUï¼Œæ²¡æœ‰ GPUï¼Œè¿™é‡Œæˆ‘æ˜¯åœ¨æœ¬åœ°çš„æœåŠ¡å™¨ä¸Šå»ºç«‹äº†ä¸€å°è™šæ‹Ÿæœº</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsb_release -a</span></span><br><span class="line"></span><br><span class="line">No LSB modules are available.</span><br><span class="line">Distributor ID:	Ubuntu</span><br><span class="line">Description:	Ubuntu <span class="number">24.04</span><span class="number">.1</span> LTS</span><br><span class="line">Release:	<span class="number">24.04</span></span><br><span class="line">Codename:	noble</span><br></pre></td></tr></table></figure><h4 id="1-2-conda-å®‰è£…"><a href="#1-2-conda-å®‰è£…" class="headerlink" title="1.2 conda å®‰è£…"></a>1.2 conda å®‰è£…</h4><div class="note info"><p>python ç¯å¢ƒï¼Œä½¿ç”¨çš„æ˜¯ <code>Miniconda</code><br>å®‰è£…ç›´æ¥å‚è€ƒå®˜æ–¹æ–‡æ¡£å³å¯ï¼š<a target="_blank" rel="noopener external nofollow noreferrer" href="https://docs.anaconda.com/miniconda/#quick-command-line-install">https://docs.anaconda.com/miniconda/#quick-command-line-install</a></p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/miniconda3</span><br><span class="line">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh</span><br><span class="line">bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3</span><br><span class="line">rm -rf ~/miniconda3/miniconda.sh</span><br></pre></td></tr></table></figure><p>ç„¶åæ¿€æ´» miniconda</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda init bash</span><br><span class="line"></span><br><span class="line">source /root/.bashrc</span><br></pre></td></tr></table></figure><h4 id="1-3-conda-é•œåƒè®¾ç½®"><a href="#1-3-conda-é•œåƒè®¾ç½®" class="headerlink" title="1.3 conda é•œåƒè®¾ç½®"></a>1.3 conda é•œåƒè®¾ç½®</h4><p>é…ç½®é•œåƒæ˜¯ä¸ºäº†åŠ é€Ÿå®‰è£…åŒ…ï¼Œä½¿ç”¨çš„æ˜¯ <code>æ¸…åå¤§å­¦</code> é•œåƒ<br>æ£€æŸ¥ç”¨æˆ·ç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨ <code>.condarc</code>ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œåˆ™é€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿›è¡Œåˆ›å»º</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure><p>ç„¶åæ‰“å¼€ .condarc æ–‡ä»¶ï¼Œè®¾ç½®æ¸…åå¤§å­¦é•œåƒ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">show_channel_urls: true</span><br><span class="line">channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - defaults</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure><p>ä¿å­˜åï¼Œé€šè¿‡ conda info æŸ¥çœ‹é…ç½®æ˜¯å¦ç”Ÿæ•ˆ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">(base) root@local:~<span class="comment"># conda info</span></span><br><span class="line"></span><br><span class="line">     active environment : base</span><br><span class="line">    active env location : /root/miniconda3</span><br><span class="line">            shell level : <span class="number">1</span></span><br><span class="line">       user config file : /root/.condarc</span><br><span class="line"> populated config files : /root/.condarc</span><br><span class="line">          conda version : <span class="number">24.7</span><span class="number">.1</span></span><br><span class="line">    conda-build version : <span class="keyword">not</span> installed</span><br><span class="line">         python version : <span class="number">3.12</span><span class="number">.4</span>.final<span class="number">.0</span></span><br><span class="line">                 solver : libmamba (default)</span><br><span class="line">       virtual packages : __archspec=<span class="number">1</span>=haswell</span><br><span class="line">                          __conda=<span class="number">24.7</span><span class="number">.1</span>=<span class="number">0</span></span><br><span class="line">                          __glibc=<span class="number">2.39</span>=<span class="number">0</span></span><br><span class="line">                          __linux=<span class="number">6.8</span><span class="number">.0</span>=<span class="number">0</span></span><br><span class="line">                          __unix=<span class="number">0</span>=<span class="number">0</span></span><br><span class="line">       base environment : /root/miniconda3  (writable)</span><br><span class="line">      conda av data <span class="built_in">dir</span> : /root/miniconda3/etc/conda</span><br><span class="line">  conda av metadata url : <span class="literal">None</span></span><br><span class="line">           channel URLs : https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-<span class="number">64</span></span><br><span class="line">                          https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/noarch</span><br><span class="line">                          https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/linux-<span class="number">64</span></span><br><span class="line">                          https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/noarch</span><br><span class="line">                          https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/linux-<span class="number">64</span></span><br><span class="line">                          https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/noarch</span><br><span class="line">                          https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-<span class="number">64</span></span><br><span class="line">                          https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/noarch</span><br><span class="line">                          https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/linux-<span class="number">64</span></span><br><span class="line">                          https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/noarch</span><br><span class="line">                          https://repo.anaconda.com/pkgs/main/linux-<span class="number">64</span></span><br><span class="line">                          https://repo.anaconda.com/pkgs/main/noarch</span><br><span class="line">                          https://repo.anaconda.com/pkgs/r/linux-<span class="number">64</span></span><br><span class="line">                          https://repo.anaconda.com/pkgs/r/noarch</span><br><span class="line">          package cache : /root/miniconda3/pkgs</span><br><span class="line">                          /root/.conda/pkgs</span><br><span class="line">       envs directories : /root/miniconda3/envs</span><br><span class="line">                          /root/.conda/envs</span><br><span class="line">               platform : linux-<span class="number">64</span></span><br><span class="line">             user-agent : conda/<span class="number">24.7</span><span class="number">.1</span> requests/<span class="number">2.32</span><span class="number">.3</span> CPython/<span class="number">3.12</span><span class="number">.4</span> Linux/<span class="number">6.8</span><span class="number">.0</span>-<span class="number">47</span>-generic ubuntu/<span class="number">24.04</span><span class="number">.1</span> glibc/<span class="number">2.39</span> solver/libmamba conda-libmamba-solver/<span class="number">24.7</span><span class="number">.0</span> libmambapy/<span class="number">1.5</span><span class="number">.8</span> aau/<span class="number">0.4</span><span class="number">.4</span> c/. s/. e/.</span><br><span class="line">                UID:GID : <span class="number">0</span>:<span class="number">0</span></span><br><span class="line">             netrc file : <span class="literal">None</span></span><br><span class="line">           offline mode : <span class="literal">False</span></span><br></pre></td></tr></table></figure><h4 id="1-4-åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ"><a href="#1-4-åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ" class="headerlink" title="1.4 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ"></a>1.4 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ</h4><p>åˆ›å»ºç¯å¢ƒåä¸º <code>ravllm</code> çš„è™šæ‹Ÿç¯å¢ƒï¼Œä½¿ç”¨çš„æ˜¯ <code>Python 3.10</code>ï¼Œç„¶åæ¿€æ´»</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda create --name ravllM python=<span class="number">3.10</span> -y</span><br><span class="line"></span><br><span class="line">conda activate ravllM</span><br></pre></td></tr></table></figure><h4 id="1-5-å®‰è£…-vllm"><a href="#1-5-å®‰è£…-vllm" class="headerlink" title="1.5 å®‰è£… vllm"></a>1.5 å®‰è£… vllm</h4><p>å› ä¸º vllm é»˜è®¤æ”¯æŒ GPUï¼Œæ‰€ä»¥éœ€è¦å®‰è£… CPU ç‰ˆæœ¬ï¼Œåˆ™éœ€è¦è‡ªè¡Œç¼–è¯‘å®‰è£…</p><div class="note success"><p>ğŸ”¥ å¦‚æœä½ æœ‰ GPU æ˜¾å¡ï¼Œå»ºè®®ç›´æ¥ä½¿ç”¨ GPU ç‰ˆæœ¬</p></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install vllm</span><br></pre></td></tr></table></figure><hr><div class="note success"><p>ğŸ”¥ å¦‚æœä½ æ²¡æœ‰ GPU æ˜¾å¡ï¼Œå¦‚æœç”¨ CPU ç‰ˆæœ¬ï¼Œåˆ™éœ€è¦è‡ªè¡Œç¼–è¯‘å®‰è£…</p></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">å®‰è£… gcc ç¼–è¯‘å™¨</span></span><br><span class="line">apt update  -y</span><br><span class="line">apt install -y gcc-12 g++-12 libnuma-dev</span><br><span class="line">update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12</span><br><span class="line">apt install -y cmake</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">å…‹éš† vllm ä»“åº“</span></span><br><span class="line">mkdir ~/codespace &amp;&amp; cd ~/codespace</span><br><span class="line">git clone https://github.com/vllm-project/vllm.git vllm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">å®‰è£… vllm ä»“åº“æ‰€éœ€çš„ä¾èµ–</span></span><br><span class="line">cd vllm</span><br><span class="line">pip install wheel packaging ninja &quot;setuptools&gt;=49.4.0&quot; numpy</span><br><span class="line">pip install -v -r requirements-cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">æ‰“åŒ…å®‰è£…</span></span><br><span class="line">VLLM_TARGET_DEVICE=cpu python setup.py install</span><br></pre></td></tr></table></figure><h3 id="2-å¤§æ¨¡å‹ä¸‹è½½"><a href="#2-å¤§æ¨¡å‹ä¸‹è½½" class="headerlink" title="2 å¤§æ¨¡å‹ä¸‹è½½"></a>2 å¤§æ¨¡å‹ä¸‹è½½</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">å®‰è£… git ç¯å¢ƒ</span></span><br><span class="line">apt install -y git git-lfs</span><br><span class="line">git lfs install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">é€šè¿‡ git ä¸‹è½½å¤§æ¨¡å‹</span></span><br><span class="line">mkdir -p ~/modelspace &amp;&amp; cd ~/modelspace</span><br><span class="line">git clone https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct Qwen2.5-1.5B-Instruct</span><br></pre></td></tr></table></figure><div class="note info"><p><strong>æ³¨æ„ï¼š</strong></p><ul><li>å¦‚æœä» <a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/">https://huggingface.co</a> ä¸‹è½½è¾ƒæ…¢ï¼Œå¯ä»¥ä»å›½å†…çš„ <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/">https://www.modelscope.cn</a> è¿›è¡Œä¸‹è½½</li><li>å½“ç„¶ä¹Ÿå¯ä»¥é€šè¿‡ sdk æˆ–è€…å‘½ä»¤è¡Œçš„æ–¹å¼è¿›è¡Œä¸‹è½½ï¼Œå¯ä»¥è‡ªè¡Œå‚è€ƒå®˜æ–¹æ–‡æ¡£</li></ul></div><p>clone å®Œåï¼ŒæŸ¥çœ‹ä¸‹å¤§æ¨¡å‹ç›®å½•ç»“æ„</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(base) root@local:~/modelspace/Qwen2.5-1.5B-Instruct# ls -lah</span><br><span class="line">total 2.9G</span><br><span class="line">drwxr-xr-x 3 root root 4.0K Oct 30 06:05 .</span><br><span class="line">drwxr-xr-x 5 root root 4.0K Oct 30 07:11 ..</span><br><span class="line">-rw-r--r-- 1 root root  660 Oct 30 06:05 config.json</span><br><span class="line">-rw-r--r-- 1 root root  242 Oct 30 06:05 generation_config.json</span><br><span class="line">drwxr-xr-x 8 root root 4.0K Oct 30 06:07 .git</span><br><span class="line">-rw-r--r-- 1 root root 1.5K Oct 30 06:05 .gitattributes</span><br><span class="line">-rw-r--r-- 1 root root  12K Oct 30 06:05 LICENSE</span><br><span class="line">-rw-r--r-- 1 root root 1.6M Oct 30 06:05 merges.txt</span><br><span class="line">-rw-r--r-- 1 root root 2.9G Oct 30 06:05 model.safetensors</span><br><span class="line">-rw-r--r-- 1 root root 4.9K Oct 30 06:05 README.md</span><br><span class="line">-rw-r--r-- 1 root root 7.2K Oct 30 06:05 tokenizer_config.json</span><br><span class="line">-rw-r--r-- 1 root root 6.8M Oct 30 06:05 tokenizer.json</span><br><span class="line">-rw-r--r-- 1 root root 2.7M Oct 30 06:05 vocab.json</span><br></pre></td></tr></table></figure><h3 id="3-æ¨ç†-ç¦»çº¿æ¨ç†"><a href="#3-æ¨ç†-ç¦»çº¿æ¨ç†" class="headerlink" title="3 æ¨ç† - ç¦»çº¿æ¨ç†"></a>3 æ¨ç† - ç¦»çº¿æ¨ç†</h3><p>ç›´æ¥é€šè¿‡ python è„šæœ¬æ¥è°ƒç”¨æ¨¡å‹ï¼Œè€Œä¸æ˜¯é€šè¿‡ api çš„æ–¹å¼è¿›è¡Œè°ƒç”¨</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> LLM, SamplingParams</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®ç¯å¢ƒå˜é‡</span></span><br><span class="line">os.environ[<span class="string">&#x27;VLLM_TARGET_DEVICE&#x27;</span>] = <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸‹è½½çš„æ¨¡å‹æƒé‡æ–‡ä»¶ç›®å½•</span></span><br><span class="line">model_dir = <span class="string">&#x27;/root/modelspace/Qwen2.5-1.5B-Instruct&#x27;</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(</span><br><span class="line">    model_dir,</span><br><span class="line">    local_files_only=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    &#123;<span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;system&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: <span class="string">&#x27;You are a helpful assistant.&#x27;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: <span class="string">&#x27;è·Ÿæˆ‘è®²è®²è‚¡å¸‚è¿è¡Œçš„é€»è¾‘&#x27;</span>&#125;</span><br><span class="line">]</span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tokenize=<span class="literal">False</span>,</span><br><span class="line">    add_generation_prompt=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm = LLM(</span><br><span class="line">    model=model_dir,</span><br><span class="line">    tensor_parallel_size=<span class="number">1</span>,</span><br><span class="line">    device=<span class="string">&#x27;cpu&#x27;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sampling_params = SamplingParams(temperature=<span class="number">0.7</span>, top_p=<span class="number">0.8</span>, repetition_penalty=<span class="number">1.05</span>, max_tokens=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">outputs = llm.generate([text], sampling_params)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> output <span class="keyword">in</span> outputs:</span><br><span class="line">    prompt = output.prompt</span><br><span class="line">    generated_text = output.outputs[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;æç¤ºè¯ï¼š<span class="subst">&#123;prompt!r&#125;</span>, å¤§æ¨¡å‹æ¨ç†ç»“æœè¾“å‡ºï¼š<span class="subst">&#123;generated_text!r&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p>ç„¶ååœ¨æ¿€æ´»çš„ ravllm ç¯å¢ƒä¸‹è¿è¡Œæ­¤è„šæœ¬ï¼Œåœ¨ç»“æœæœªè¾“å‡ºä¹‹å‰ï¼Œçœ‹ä¸‹å†…å­˜å’Œ CPU çš„çŠ¶æ€<br><img data-src="/posts/51728/cpu-status.png" alt="cpu-status.png"></p><p>å¯ä»¥çœ‹åˆ° 16 æ ¸çš„ CPU éƒ½åœ¨åŠªåŠ›çš„å·¥ä½œã€‚</p><p>æ¨ç†ç»“æŸï¼Œæ¨ç†ç»“æœå¦‚ä¸‹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">(ravllm) root@local:~/lmcode/25# python local.py</span><br><span class="line">INFO 10-31 08:51:52 importing.py:13] Triton not installed; certain</span><br><span class="line">GPU-related functions will not be available.</span><br><span class="line">WARNING 10-31 08:52:02 config.py:421] Async output processing is</span><br><span class="line">only supported for CUDA, TPU, XPU. Disabling it for other platforms.</span><br><span class="line"></span><br><span class="line">INFO 10-31 08:52:02 llm_engine.py:240] Initializing an LLM engine</span><br><span class="line">(v0.6.3.post2.dev76+g51c24c97) with config: model=&#x27;/root/modelspace/</span><br><span class="line">Qwen2.5-1.5B-Instruct&#x27;, speculative_config=None, tokenizer=&#x27;/root/</span><br><span class="line">modelspace/Qwen2.5-1.5B-Instruct&#x27;, skip_tokenizer_init=False,</span><br><span class="line">tokenizer_mode=auto, revision=None, override_neuron_config=None,</span><br><span class="line">rope_scaling=None, rope_theta=None, tokenizer_revision=None,</span><br><span class="line">trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768,</span><br><span class="line">download_dir=None, load_format=LoadFormat.AUTO,</span><br><span class="line">tensor_parallel_size=1, pipeline_parallel_size=1,</span><br><span class="line">disable_custom_all_reduce=False, quantization=None,</span><br><span class="line">enforce_eager=False, kv_cache_dtype=auto,</span><br><span class="line">quantization_param_path=None, device_config=cpu,</span><br><span class="line">decoding_config=DecodingConfig(guided_decoding_backend=&#x27;outlines&#x27;),</span><br><span class="line">observability_config=ObservabilityConfig(otlp_traces_endpoint=None,</span><br><span class="line">collect_model_forward_time=False, collect_model_execute_time=False),</span><br><span class="line">seed=0, served_model_name=/root/modelspace/Qwen2.5-1.5B-Instruct,</span><br><span class="line">num_scheduler_steps=1, chunked_prefill_enabled=False</span><br><span class="line">multi_step_stream_outputs=True, enable_prefix_caching=False,</span><br><span class="line">use_async_output_proc=False, use_cached_outputs=False,</span><br><span class="line">mm_processor_kwargs=None)</span><br><span class="line"></span><br><span class="line">WARNING 10-31 08:52:03 cpu_executor.py:332] CUDA graph is not</span><br><span class="line">supported on CPU, fallback to the eager mode.</span><br><span class="line"></span><br><span class="line">WARNING 10-31 08:52:03 cpu_executor.py:362] Environment variable</span><br><span class="line">VLLM_CPU_KVCACHE_SPACE (GB) for CPU backend is not set, using 4 by</span><br><span class="line">default.</span><br><span class="line">INFO 10-31 08:52:03 selector.py:193]</span><br><span class="line">Cannot use _Backend.FLASH_ATTN backend on CPU.</span><br><span class="line">INFO 10-31 08:52:03 selector.py:131] Using Torch SDPA backend.</span><br><span class="line">INFO 10-31 08:52:03 selector.py:193]</span><br><span class="line">Cannot use _Backend.FLASH_ATTN backend on CPU.</span><br><span class="line">INFO 10-31 08:52:03 selector.py:131] Using Torch SDPA backend.</span><br><span class="line">Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00&lt;?, ?it/s]</span><br><span class="line">Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00&lt;00:00,  1.43it/s]</span><br><span class="line">Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00&lt;00:00,  1.43it/s]</span><br><span class="line"></span><br><span class="line">INFO 10-31 08:52:05 cpu_executor.py:214] # CPU blocks: 9362</span><br><span class="line">Processed prompts:   0%|                  | 0/1</span><br><span class="line">[00:00&lt;?, ?it/s, eProcessed prompts: 100%|â–ˆ| 1/1</span><br><span class="line">[07:28&lt;00:00 44833s Processed prompts: 100%|â–ˆ| 1/1</span><br><span class="line">[07:28&lt;00:00, 448.33s</span><br><span class="line">Promptæç¤ºè¯:</span><br><span class="line">&#x27;&lt;|im_start|&gt;system\nYou are a helpful assistant.&lt;|im_end|&gt;\n</span><br><span class="line">&lt;|im_start|&gt;user\nè·Ÿæˆ‘è®²è®²è‚¡å¸‚è¿è¡Œçš„é€»è¾‘&lt;|im_end|&gt;\n</span><br><span class="line">&lt;|im_start|&gt;assistant\n&#x27;,</span><br><span class="line">å¤§æ¨¡å‹æ¨ç†è¾“å‡º: &#x27;è‚¡å¸‚æ˜¯ä¸€ä¸ªå¤æ‚çš„å¸‚åœºï¼Œå…¶è¿è¡Œå—åˆ°å¤šç§</span><br><span class="line">å› ç´ çš„å½±å“ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›åŸºæœ¬çš„é€»è¾‘ï¼š\n\n1. ä¾›æ±‚å…³ç³»ï¼šè‚¡ç¥¨ä»·æ ¼é€šå¸¸ç”±ä¾›ç»™å’Œéœ€æ±‚å†³å®šã€‚</span><br><span class="line">å¦‚æœå¸‚åœºä¸Šæœ‰æ›´å¤šçš„äººæƒ³è¦è´­ä¹°è‚¡ç¥¨ï¼Œè€Œä¾›åº”è€…å´æœ‰é™ï¼Œé‚£ä¹ˆè‚¡ç¥¨çš„ä»·æ ¼å°±ä¼šä¸Šå‡ã€‚åä¹‹ï¼Œå¦‚</span><br><span class="line">æœä¾›åº”é‡å¤§äºéœ€æ±‚é‡ï¼Œè‚¡ç¥¨çš„ä»·æ ¼å°±ä¼šä¸‹é™ã€‚\n\n2. å…¬å¸åŸºæœ¬é¢ï¼šå…¬å¸çš„è´¢åŠ¡çŠ¶å†µã€ç›ˆåˆ©èƒ½</span><br><span class="line">åŠ›ã€å¢é•¿æ½œåŠ›ç­‰å› ç´ éƒ½ä¼šå½±å“è‚¡ç¥¨ä»·æ ¼ã€‚æŠ•èµ„è€…ä¼šå…³æ³¨å…¬å¸çš„ç›ˆåˆ©é¢„æµ‹ã€å¸‚ç›ˆç‡ã€è‚¡æ¯æ”¯ä»˜ç­‰</span><br><span class="line">æŒ‡æ ‡ã€‚\n\n3. å¸‚åœºæƒ…ç»ªï¼šå¸‚åœºæƒ…ç»ªä¹Ÿä¼šå½±å“è‚¡ç¥¨ä»·æ ¼ã€‚ä¾‹å¦‚ï¼Œåœ¨ç»æµè¡°é€€æ—¶æœŸï¼ŒæŠ•èµ„è€…å¯èƒ½</span><br><span class="line">ä¼šæ›´åŠ è°¨æ…ï¼Œä»è€Œå¯¼è‡´è‚¡ç¥¨ä»·æ ¼ä¸‹è·Œã€‚è€Œåœ¨ç»æµç¹è£æ—¶æœŸï¼ŒæŠ•èµ„è€…å¯èƒ½ä¼šæ›´åŠ ä¹è§‚ï¼Œå¯¼è‡´è‚¡ç¥¨</span><br><span class="line">ä»·æ ¼ä¸Šæ¶¨ã€‚\n\n4. åˆ©ç‡æ°´å¹³ï¼šåˆ©ç‡æ°´å¹³ä¹Ÿä¼šå½±å“è‚¡ç¥¨ä»·æ ¼ã€‚å½“åˆ©ç‡ä¸Šå‡æ—¶ï¼ŒæŠ•èµ„è€…å¯èƒ½ä¼šæ›´</span><br><span class="line">æ„¿æ„å°†èµ„é‡‘æŠ•èµ„äºå€ºåˆ¸ç­‰å›ºå®šæ”¶ç›Šäº§å“ï¼Œè€Œä¸æ˜¯è‚¡ç¥¨ï¼Œä»è€Œå¯¼è‡´è‚¡ç¥¨ä»·æ ¼ä¸‹è·Œã€‚ç›¸åï¼Œå½“åˆ©ç‡</span><br><span class="line">ä¸‹é™æ—¶ï¼Œè‚¡ç¥¨ä»·æ ¼å¯èƒ½ä¼šä¸Šæ¶¨ã€‚\n\n5. å¤–éƒ¨äº‹ä»¶ï¼šå¤–éƒ¨äº‹ä»¶ï¼Œå¦‚è‡ªç„¶ç¾å®³ã€æ”¿ç­–å˜åŒ–ã€åœ°ç¼˜</span><br><span class="line">æ”¿æ²»å†²çªç­‰ï¼Œä¹Ÿå¯èƒ½å¯¹è‚¡å¸‚äº§ç”Ÿé‡å¤§å½±å“ã€‚\n\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™äº›å› ç´ å¹¶ä¸æ˜¯ç‹¬ç«‹çš„ï¼Œå®ƒä»¬</span><br><span class="line">ä¹‹é—´å¯èƒ½å­˜åœ¨ç›¸äº’ä½œç”¨ã€‚æ­¤å¤–ï¼Œè‚¡å¸‚ä»·æ ¼ä¹Ÿä¼šå—åˆ°å…¶ä»–å„ç§å› ç´ çš„å½±å“ï¼Œå¦‚å…¬å¸ä¸šç»©ã€æ–°é—»æŠ¥</span><br><span class="line">é“ã€å¸‚åœºé¢„æœŸç­‰ã€‚å› æ­¤ï¼ŒæŠ•èµ„è€…éœ€è¦ç»¼åˆè€ƒè™‘å„ç§å› ç´ ï¼Œå¹¶ç»“åˆè‡ªå·±çš„æŠ•èµ„ç­–ç•¥è¿›è¡Œå†³ç­–ã€‚&#x27;</span><br></pre></td></tr></table></figure><h3 id="4-æ¨ç†-é€šè¿‡è°ƒç”¨-api"><a href="#4-æ¨ç†-é€šè¿‡è°ƒç”¨-api" class="headerlink" title="4 æ¨ç† - é€šè¿‡è°ƒç”¨ api"></a>4 æ¨ç† - é€šè¿‡è°ƒç”¨ api</h3><h4 id="4-1-éƒ¨ç½²å¤§æ¨¡å‹-api-æœåŠ¡"><a href="#4-1-éƒ¨ç½²å¤§æ¨¡å‹-api-æœåŠ¡" class="headerlink" title="4.1 éƒ¨ç½²å¤§æ¨¡å‹ api æœåŠ¡"></a>4.1 éƒ¨ç½²å¤§æ¨¡å‹ api æœåŠ¡</h4><h5 id="4-1-1-éƒ¨ç½²-api"><a href="#4-1-1-éƒ¨ç½²-api" class="headerlink" title="4.1.1 éƒ¨ç½² api"></a>4.1.1 éƒ¨ç½² api</h5><p>ä¸ç®¡æ˜¯è„šæœ¬å®¢æˆ·ç«¯è°ƒç”¨ apiï¼Œè¿˜æ˜¯ webui çš„æ–¹å¼è¿›è¡Œè°ƒç”¨ apiï¼Œé¦–å…ˆè¦åšçš„æ˜¯éƒ¨ç½²è¿è¡Œå¤§æ¨¡å‹ api æœåŠ¡</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vllm serve /root/modelspace/Qwen2.5-1.5B-Instruct</span><br><span class="line">  --served-model-name Qwen/Qwen2.5-1.5B-Instruct</span><br><span class="line">  --port 8000</span><br><span class="line">  --host 0.0.0.0</span><br><span class="line">  --device cpu</span><br><span class="line">  --disable-frontend-multiprocessing</span><br></pre></td></tr></table></figure><hr><div class="note info"><p><strong>æ³¨æ„</strong>ï¼šä¸Šé¢çš„å‘½ä»¤ä¸­ï¼Œé‡ç‚¹å…³æ³¨ä¸‹ <code>--disable-frontend-multiprocessing</code> è¿™ä¸ªå‚æ•°é€‰é¡¹ï¼Œå¦‚æœä¸æŒ‡å®šï¼Œå®¢æˆ·ç«¯è°ƒç”¨ api çš„æ—¶å€™ä¼šæŠ¥é”™ã€‚å¯èƒ½è·Ÿæˆ‘ä½¿ç”¨çš„æ¨¡å‹çš„å‚æ•°å¤§å°æœ‰å…³ç³»ï¼Œå¦‚æœæ˜¯ 0.5Bï¼Œå°±ä¸ä¼šæŠ¥é”™</p></div><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">16</span>:06 engine.py:<span class="number">297</span>] Added request</span><br><span class="line">chat-027710c78bb6449cb547ea684c82e5c0.</span><br><span class="line"></span><br><span class="line">ERROR <span class="number">11</span>-01 01:<span class="number">16</span>:<span class="number">33</span> client.py:<span class="number">262</span>] RuntimeError(<span class="string">&#x27;Engine loop has died&#x27;</span>)</span><br><span class="line">ERROR <span class="number">11</span>-01 01:<span class="number">16</span>:<span class="number">33</span> client.py:<span class="number">262</span>] Traceback (most recent call last):</span><br><span class="line"></span><br><span class="line">ERROR <span class="number">11</span>-01 01:<span class="number">16</span>:<span class="number">33</span> client.py:<span class="number">262</span>]   File <span class="string">&quot;/root/miniconda3/envs/</span></span><br><span class="line"><span class="string">ravllm/lib/python3.10/site-packages/vllm-0.6.3.post2.dev76+g51c24c97.</span></span><br><span class="line"><span class="string">cpu-py3.10-linux-x86_64.egg/vllm/engine/multiprocessing/client.py&quot;</span>,</span><br><span class="line">line <span class="number">150</span>, <span class="keyword">in</span> run_heartbeat_loop</span><br><span class="line"></span><br><span class="line">ERROR <span class="number">11</span>-01 01:<span class="number">16</span>:<span class="number">33</span> client.py:<span class="number">262</span>]     <span class="keyword">await</span> <span class="variable language_">self</span>._check_success(</span><br><span class="line">ERROR <span class="number">11</span>-01 01:<span class="number">16</span>:<span class="number">33</span> client.py:<span class="number">262</span>]   File <span class="string">&quot;/root/miniconda3/envs/</span></span><br><span class="line"><span class="string">ravllm/lib/python3.10/site-packages/vllm-0.6.3.post2.dev76+g51c24c97.</span></span><br><span class="line"><span class="string">cpu-py3.10-linux-x86_64.egg/vllm/engine/multiprocessing/client.py&quot;</span>,</span><br><span class="line">line <span class="number">326</span>, <span class="keyword">in</span> _check_success</span><br><span class="line"></span><br><span class="line">ERROR <span class="number">11</span>-01 01:<span class="number">16</span>:<span class="number">33</span> client.py:<span class="number">262</span>]     <span class="keyword">raise</span> response</span><br><span class="line">ERROR <span class="number">11</span>-01 01:<span class="number">16</span>:<span class="number">33</span> client.py:<span class="number">262</span>] RuntimeError: Engine loop has died</span><br><span class="line">CRITICAL <span class="number">11</span>-01 01:<span class="number">16</span>:<span class="number">43</span> launcher.py:<span class="number">99</span>] MQLLMEngine <span class="keyword">is</span> already dead,</span><br><span class="line">terminating server process</span><br><span class="line"></span><br><span class="line">INFO:     <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">42718</span> - <span class="string">&quot;POST /v1/chat/completions HTTP/1.1&quot;</span></span><br><span class="line">                            <span class="number">500</span> Internal Server Error</span><br><span class="line">INFO:     Shutting down</span><br><span class="line">INFO:     Waiting <span class="keyword">for</span> application shutdown.</span><br><span class="line">INFO:     Application shutdown complete.</span><br><span class="line">INFO:     Finished server process [<span class="number">124376</span>]</span><br><span class="line"></span><br><span class="line">(ravllm) root@local:~<span class="comment"># /root/miniconda3/envs/ravllm/lib/python3.10/</span></span><br><span class="line">multiprocessing/resource_tracker.py:<span class="number">224</span>: UserWarning:</span><br><span class="line">resource_tracker: There appear to be <span class="number">1</span> leaked semaphore objects to</span><br><span class="line">clean up at shutdown</span><br><span class="line">  warnings.warn(<span class="string">&#x27;resource_tracker: There appear to be %d &#x27;</span></span><br></pre></td></tr></table></figure><div class="note danger"><p>ğŸ†˜ ğŸ†˜ ğŸ†˜<br><strong>æŸ¥é˜…äº†èµ„æ–™ï¼Œç›®å‰è¿˜æ²¡æœ‰æ‰¾å‡ºå…·ä½“åŸå› ï¼ˆç½‘ä¸Šçš„èµ„æ–™è¯´ä»€ä¹ˆçš„éƒ½æœ‰ï¼Œéƒ½ä¸èƒ½è§£å†³é—®é¢˜ï¼‰</strong></p></div><p>ğŸš€ æ­£å¸¸å¯åŠ¨æœåŠ¡åï¼Œè¿è¡Œå¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">(ravllm) root@local:~<span class="comment"># vllm serve /root/modelspace/Qwen2.5-1.5B-Instruct --served-model-name Qwen/Qwen2.5-1.5B-Instruct --port 8000 --host 0.0.0.0 --device cpu --disable-frontend-multiprocessing</span></span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">42</span> importing.py:<span class="number">13</span>] Triton <span class="keyword">not</span> installed; certain GPU-related functions will <span class="keyword">not</span> be available.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">45</span> api_server.py:<span class="number">528</span>] vLLM API server version <span class="number">0.6</span><span class="number">.3</span>.post2.dev76+g51c24c97</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">45</span> api_server.py:<span class="number">529</span>] args: Namespace(subparser=<span class="string">&#x27;serve&#x27;</span>, model_tag=<span class="string">&#x27;/root/modelspace/Qwen2.5-1.5B-Instruct&#x27;</span>, config=<span class="string">&#x27;&#x27;</span>, host=<span class="string">&#x27;0.0.0.0&#x27;</span>, port=<span class="number">8000</span>, uvicorn_log_level=<span class="string">&#x27;info&#x27;</span>, allow_credentials=<span class="literal">False</span>, allowed_origins=[<span class="string">&#x27;*&#x27;</span>], allowed_methods=[<span class="string">&#x27;*&#x27;</span>], allowed_headers=[<span class="string">&#x27;*&#x27;</span>], api_key=<span class="literal">None</span>, lora_modules=<span class="literal">None</span>, prompt_adapters=<span class="literal">None</span>, chat_template=<span class="literal">None</span>, response_role=<span class="string">&#x27;assistant&#x27;</span>, ssl_keyfile=<span class="literal">None</span>, ssl_certfile=<span class="literal">None</span>, ssl_ca_certs=<span class="literal">None</span>, ssl_cert_reqs=<span class="number">0</span>, root_path=<span class="literal">None</span>, middleware=[], return_tokens_as_token_ids=<span class="literal">False</span>, disable_frontend_multiprocessing=<span class="literal">True</span>, enable_auto_tool_choice=<span class="literal">False</span>, tool_call_parser=<span class="literal">None</span>, tool_parser_plugin=<span class="string">&#x27;&#x27;</span>, model=<span class="string">&#x27;/root/modelspace/Qwen2.5-1.5B-Instruct&#x27;</span>, task=<span class="string">&#x27;auto&#x27;</span>, tokenizer=<span class="literal">None</span>, skip_tokenizer_init=<span class="literal">False</span>, revision=<span class="literal">None</span>, code_revision=<span class="literal">None</span>, tokenizer_revision=<span class="literal">None</span>, tokenizer_mode=<span class="string">&#x27;auto&#x27;</span>, trust_remote_code=<span class="literal">False</span>, download_dir=<span class="literal">None</span>, load_format=<span class="string">&#x27;auto&#x27;</span>, config_format=&lt;ConfigFormat.AUTO: <span class="string">&#x27;auto&#x27;</span>&gt;, dtype=<span class="string">&#x27;auto&#x27;</span>, kv_cache_dtype=<span class="string">&#x27;auto&#x27;</span>, quantization_param_path=<span class="literal">None</span>, max_model_len=<span class="literal">None</span>, guided_decoding_backend=<span class="string">&#x27;outlines&#x27;</span>, distributed_executor_backend=<span class="literal">None</span>, worker_use_ray=<span class="literal">False</span>, pipeline_parallel_size=<span class="number">1</span>, tensor_parallel_size=<span class="number">1</span>, max_parallel_loading_workers=<span class="literal">None</span>, ray_workers_use_nsight=<span class="literal">False</span>, block_size=<span class="number">16</span>, enable_prefix_caching=<span class="literal">False</span>, disable_sliding_window=<span class="literal">False</span>, use_v2_block_manager=<span class="literal">False</span>, num_lookahead_slots=<span class="number">0</span>, seed=<span class="number">0</span>, swap_space=<span class="number">4</span>, cpu_offload_gb=<span class="number">0</span>, gpu_memory_utilization=<span class="number">0.9</span>, num_gpu_blocks_override=<span class="literal">None</span>, max_num_batched_tokens=<span class="literal">None</span>, max_num_seqs=<span class="number">256</span>, max_logprobs=<span class="number">20</span>, disable_log_stats=<span class="literal">False</span>, quantization=<span class="literal">None</span>, rope_scaling=<span class="literal">None</span>, rope_theta=<span class="literal">None</span>, enforce_eager=<span class="literal">False</span>, max_context_len_to_capture=<span class="literal">None</span>, max_seq_len_to_capture=<span class="number">8192</span>, disable_custom_all_reduce=<span class="literal">False</span>, tokenizer_pool_size=<span class="number">0</span>, tokenizer_pool_type=<span class="string">&#x27;ray&#x27;</span>, tokenizer_pool_extra_config=<span class="literal">None</span>, limit_mm_per_prompt=<span class="literal">None</span>, mm_processor_kwargs=<span class="literal">None</span>, enable_lora=<span class="literal">False</span>, max_loras=<span class="number">1</span>, max_lora_rank=<span class="number">16</span>, lora_extra_vocab_size=<span class="number">256</span>, lora_dtype=<span class="string">&#x27;auto&#x27;</span>, long_lora_scaling_factors=<span class="literal">None</span>, max_cpu_loras=<span class="literal">None</span>, fully_sharded_loras=<span class="literal">False</span>, enable_prompt_adapter=<span class="literal">False</span>, max_prompt_adapters=<span class="number">1</span>, max_prompt_adapter_token=<span class="number">0</span>, device=<span class="string">&#x27;cpu&#x27;</span>, num_scheduler_steps=<span class="number">1</span>, multi_step_stream_outputs=<span class="literal">True</span>, scheduler_delay_factor=<span class="number">0.0</span>, enable_chunked_prefill=<span class="literal">None</span>, speculative_model=<span class="literal">None</span>, speculative_model_quantization=<span class="literal">None</span>, num_speculative_tokens=<span class="literal">None</span>, speculative_disable_mqa_scorer=<span class="literal">False</span>, speculative_draft_tensor_parallel_size=<span class="literal">None</span>, speculative_max_model_len=<span class="literal">None</span>, speculative_disable_by_batch_size=<span class="literal">None</span>, ngram_prompt_lookup_max=<span class="literal">None</span>, ngram_prompt_lookup_min=<span class="literal">None</span>, spec_decoding_acceptance_method=<span class="string">&#x27;rejection_sampler&#x27;</span>, typical_acceptance_sampler_posterior_threshold=<span class="literal">None</span>, typical_acceptance_sampler_posterior_alpha=<span class="literal">None</span>, disable_logprobs_during_spec_decoding=<span class="literal">None</span>, model_loader_extra_config=<span class="literal">None</span>, ignore_patterns=[], preemption_mode=<span class="literal">None</span>, served_model_name=[<span class="string">&#x27;Qwen/Qwen2.5-1.5B-Instruct&#x27;</span>], qlora_adapter_name_or_path=<span class="literal">None</span>, otlp_traces_endpoint=<span class="literal">None</span>, collect_detailed_traces=<span class="literal">None</span>, disable_async_output_proc=<span class="literal">False</span>, override_neuron_config=<span class="literal">None</span>, scheduling_policy=<span class="string">&#x27;fcfs&#x27;</span>, disable_log_requests=<span class="literal">False</span>, max_log_len=<span class="literal">None</span>, disable_fastapi_docs=<span class="literal">False</span>, dispatch_function=&lt;function serve at <span class="number">0x7602e53ec700</span>&gt;)</span><br><span class="line">WARNING <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">52</span> arg_utils.py:<span class="number">1038</span>] [DEPRECATED] Block manager v1 has been removed, <span class="keyword">and</span> setting --use-v2-block-manager to <span class="literal">True</span> <span class="keyword">or</span> <span class="literal">False</span> has no effect on vLLM behavior. Please remove --use-v2-block-manager <span class="keyword">in</span> your engine argument. If your use <span class="keyword">case</span> <span class="keyword">is</span> <span class="keyword">not</span> supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue <span class="keyword">with</span> detailed information.</span><br><span class="line">WARNING <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">52</span> config.py:<span class="number">421</span>] Async output processing <span class="keyword">is</span> only supported <span class="keyword">for</span> CUDA, TPU, XPU. Disabling it <span class="keyword">for</span> other platforms.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">52</span> llm_engine.py:<span class="number">240</span>] Initializing an LLM engine (v0<span class="number">.6</span><span class="number">.3</span>.post2.dev76+g51c24c97) <span class="keyword">with</span> config: model=<span class="string">&#x27;/root/modelspace/Qwen2.5-1.5B-Instruct&#x27;</span>, speculative_config=<span class="literal">None</span>, tokenizer=<span class="string">&#x27;/root/modelspace/Qwen2.5-1.5B-Instruct&#x27;</span>, skip_tokenizer_init=<span class="literal">False</span>, tokenizer_mode=auto, revision=<span class="literal">None</span>, override_neuron_config=<span class="literal">None</span>, rope_scaling=<span class="literal">None</span>, rope_theta=<span class="literal">None</span>, tokenizer_revision=<span class="literal">None</span>, trust_remote_code=<span class="literal">False</span>, dtype=torch.bfloat16, max_seq_len=<span class="number">32768</span>, download_dir=<span class="literal">None</span>, load_format=LoadFormat.AUTO, tensor_parallel_size=<span class="number">1</span>, pipeline_parallel_size=<span class="number">1</span>, disable_custom_all_reduce=<span class="literal">False</span>, quantization=<span class="literal">None</span>, enforce_eager=<span class="literal">False</span>, kv_cache_dtype=auto, quantization_param_path=<span class="literal">None</span>, device_config=cpu, decoding_config=DecodingConfig(guided_decoding_backend=<span class="string">&#x27;outlines&#x27;</span>), observability_config=ObservabilityConfig(otlp_traces_endpoint=<span class="literal">None</span>, collect_model_forward_time=<span class="literal">False</span>, collect_model_execute_time=<span class="literal">False</span>), seed=<span class="number">0</span>, served_model_name=Qwen/Qwen2<span class="number">.5</span>-<span class="number">1.5</span>B-Instruct, num_scheduler_steps=<span class="number">1</span>, chunked_prefill_enabled=<span class="literal">False</span> multi_step_stream_outputs=<span class="literal">True</span>, enable_prefix_caching=<span class="literal">False</span>, use_async_output_proc=<span class="literal">False</span>, use_cached_outputs=<span class="literal">False</span>, mm_processor_kwargs=<span class="literal">None</span>)</span><br><span class="line">WARNING <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">53</span> cpu_executor.py:<span class="number">332</span>] CUDA graph <span class="keyword">is</span> <span class="keyword">not</span> supported on CPU, fallback to the eager mode.</span><br><span class="line">WARNING <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">53</span> cpu_executor.py:<span class="number">362</span>] Environment variable VLLM_CPU_KVCACHE_SPACE (GB) <span class="keyword">for</span> CPU backend <span class="keyword">is</span> <span class="keyword">not</span> <span class="built_in">set</span>, using <span class="number">4</span> by default.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">56</span> importing.py:<span class="number">13</span>] Triton <span class="keyword">not</span> installed; certain GPU-related functions will <span class="keyword">not</span> be available.</span><br><span class="line">(VllmWorkerProcess pid=<span class="number">124634</span>) INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">59</span> selector.py:<span class="number">193</span>] Cannot use _Backend.FLASH_ATTN backend on CPU.</span><br><span class="line">(VllmWorkerProcess pid=<span class="number">124634</span>) INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">59</span> selector.py:<span class="number">131</span>] Using Torch SDPA backend.</span><br><span class="line">(VllmWorkerProcess pid=<span class="number">124634</span>) INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">59</span> multiproc_worker_utils.py:<span class="number">215</span>] Worker ready; awaiting tasks</span><br><span class="line">(VllmWorkerProcess pid=<span class="number">124634</span>) INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">59</span> selector.py:<span class="number">193</span>] Cannot use _Backend.FLASH_ATTN backend on CPU.</span><br><span class="line">(VllmWorkerProcess pid=<span class="number">124634</span>) INFO <span class="number">11</span>-01 01:<span class="number">33</span>:<span class="number">59</span> selector.py:<span class="number">131</span>] Using Torch SDPA backend.</span><br><span class="line">Loading safetensors checkpoint shards:   <span class="number">0</span>% Completed | <span class="number">0</span>/<span class="number">1</span> [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?it/s]</span><br><span class="line">Loading safetensors checkpoint shards: <span class="number">100</span>% Completed | <span class="number">1</span>/<span class="number">1</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>,  <span class="number">1.43</span>it/s]</span><br><span class="line">Loading safetensors checkpoint shards: <span class="number">100</span>% Completed | <span class="number">1</span>/<span class="number">1</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>,  <span class="number">1.43</span>it/s]</span><br><span class="line">(VllmWorkerProcess pid=<span class="number">124634</span>)</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:<span class="number">00</span> cpu_executor.py:<span class="number">214</span>] <span class="comment"># CPU blocks: 9362</span></span><br><span class="line">WARNING <span class="number">11</span>-01 01:<span class="number">34</span>:01 serving_embedding.py:<span class="number">200</span>] embedding_mode <span class="keyword">is</span> <span class="literal">False</span>. Embedding API will <span class="keyword">not</span> work.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">19</span>] Available routes are:</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /openapi.json, Methods: HEAD, GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /docs, Methods: HEAD, GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /docs/oauth2-redirect, Methods: HEAD, GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /redoc, Methods: HEAD, GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /health, Methods: GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /tokenize, Methods: POST</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /detokenize, Methods: POST</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /v1/models, Methods: GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /version, Methods: GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /v1/chat/completions, Methods: POST</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /v1/completions, Methods: POST</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /v1/embeddings, Methods: POST</span><br><span class="line">INFO:     Started server process [<span class="number">124595</span>]</span><br><span class="line">INFO:     Waiting <span class="keyword">for</span> application startup.</span><br><span class="line">INFO:     Application startup complete.</span><br><span class="line">INFO:     Uvicorn running on socket (<span class="string">&#x27;0.0.0.0&#x27;</span>, <span class="number">8000</span>) (Press CTRL+C to quit)</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:<span class="number">11</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.0</span> tokens/s, Running: <span class="number">0</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:<span class="number">21</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.0</span> tokens/s, Running: <span class="number">0</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br></pre></td></tr></table></figure><h5 id="4-1-2-æŸ¥çœ‹æ¥å£è·¯ç”±"><a href="#4-1-2-æŸ¥çœ‹æ¥å£è·¯ç”±" class="headerlink" title="4.1.2 æŸ¥çœ‹æ¥å£è·¯ç”±"></a>4.1.2 æŸ¥çœ‹æ¥å£è·¯ç”±</h5><p>å¯åŠ¨åï¼Œå¯ä»¥çœ‹åˆ°æš´éœ²å‡ºçš„æ¥å£è·¯ç”±</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">19</span>] Available routes are:</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /openapi.json, Methods: HEAD, GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /docs, Methods: HEAD, GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /docs/oauth2-redirect, Methods: HEAD, GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /redoc, Methods: HEAD, GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /health, Methods: GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /tokenize, Methods: POST</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /detokenize, Methods: POST</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /v1/models, Methods: GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /version, Methods: GET</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /v1/chat/completions, Methods: POST</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /v1/completions, Methods: POST</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">34</span>:01 launcher.py:<span class="number">27</span>] Route: /v1/embeddings, Methods: POST</span><br></pre></td></tr></table></figure><p>åœ¨æµè§ˆå™¨ä¸­éªŒè¯ä¸‹ä¸€ä¸ªæ¥å£ï¼Œè¿™é‡Œé€‰æ‹© <code>/v1/models</code>ï¼Œåœ¨æµè§ˆå™¨ä¸­è¾“å…¥å®Œæ•´çš„åœ°å€ï¼š<code>http://192.168.1.14:8000/v1/models</code>ï¼Œè¾“å‡ºç»“æœå¦‚ä¸‹</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;object&quot;</span><span class="punctuation">:</span> <span class="string">&quot;list&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;object&quot;</span><span class="punctuation">:</span> <span class="string">&quot;model&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;created&quot;</span><span class="punctuation">:</span> <span class="number">1730425425</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;owned_by&quot;</span><span class="punctuation">:</span> <span class="string">&quot;vllm&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;root&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/root/modelspace/Qwen2.5-1.5B-Instruct&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;parent&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;max_model_len&quot;</span><span class="punctuation">:</span> <span class="number">32768</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;permission&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;modelperm-c05e0ff5d1494dbb9668f2b0bbed42c4&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;object&quot;</span><span class="punctuation">:</span> <span class="string">&quot;model_permission&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;created&quot;</span><span class="punctuation">:</span> <span class="number">1730425425</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;allow_create_engine&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;allow_sampling&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;allow_logprobs&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;allow_search_indices&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;allow_view&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;allow_fine_tuning&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;organization&quot;</span><span class="punctuation">:</span> <span class="string">&quot;*&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;group&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;is_blocking&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h4 id="4-2-è„šæœ¬å®¢æˆ·ç«¯è°ƒç”¨-api"><a href="#4-2-è„šæœ¬å®¢æˆ·ç«¯è°ƒç”¨-api" class="headerlink" title="4.2 è„šæœ¬å®¢æˆ·ç«¯è°ƒç”¨ api"></a>4.2 è„šæœ¬å®¢æˆ·ç«¯è°ƒç”¨ api</h4><p>python è„šæœ¬å¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">openai_api_key = <span class="string">&quot;EMPTY&quot;</span></span><br><span class="line">openai_api_base = <span class="string">&quot;http://localhost:8000/v1&quot;</span></span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=openai_api_key,</span><br><span class="line">    base_url=openai_api_base,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chat_response = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&#x27;Qwen/Qwen2.5-1.5B-Instruct&#x27;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>,</span><br><span class="line">          <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are Qwen. You are a helpful assistant.&quot;</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,</span><br><span class="line">          <span class="string">&quot;content&quot;</span>: <span class="string">&quot;è¯¦ç»†è®²è§£ä¸‹è‚¡å¸‚è¿è¡Œçš„åŸç†&quot;</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">    ],</span><br><span class="line">    temperature=<span class="number">0.7</span>,</span><br><span class="line">    top_p=<span class="number">0.8</span>,</span><br><span class="line">    max_tokens=<span class="number">512</span>,</span><br><span class="line">    extra_body=&#123;</span><br><span class="line">        <span class="string">&quot;repetition_penalty&quot;</span>: <span class="number">1.05</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    timeout=<span class="number">1800</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Chat response:&quot;</span>, chat_response)</span><br></pre></td></tr></table></figure><p>è¿è¡Œè„šæœ¬åï¼ŒæŸ¥çœ‹ä¸‹ api æœåŠ¡ç«¯çš„æ—¥å¿—</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">50</span>:<span class="number">17</span> logger.py:<span class="number">37</span>] Received request</span><br><span class="line">chat-2eea5af7a0f9416abdd7b625863de374: prompt: <span class="string">&#x27;&lt;|im_start|</span></span><br><span class="line"><span class="string">&gt;system\nYou are Qwen, created by Alibaba Cloud. You are a helpful</span></span><br><span class="line"><span class="string">assistant.&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nè¯¦ç»†è®²è§£ä¸‹è‚¡å¸‚è¿è¡Œçš„åŸç†&lt;|im_end|</span></span><br><span class="line"><span class="string">&gt;\n&lt;|im_start|&gt;assistant\n&#x27;</span>, params: SamplingParams(n=<span class="number">1</span>,</span><br><span class="line">presence_penalty=<span class="number">0.0</span>, frequency_penalty=<span class="number">0.0</span>, repetition_penalty=<span class="number">1.05</span>,</span><br><span class="line">temperature=<span class="number">0.7</span>, top_p=<span class="number">0.8</span>, top_k=-<span class="number">1</span>, min_p=<span class="number">0.0</span>, seed=<span class="literal">None</span>, stop=[],</span><br><span class="line">stop_token_ids=[], include_stop_str_in_output=<span class="literal">False</span>, ignore_eos=<span class="literal">False</span>,</span><br><span class="line">max_tokens=<span class="number">512</span>, min_tokens=<span class="number">0</span>, logprobs=<span class="literal">None</span>, prompt_logprobs=<span class="literal">None</span>,</span><br><span class="line">skip_special_tokens=<span class="literal">True</span>, spaces_between_special_tokens=<span class="literal">True</span>,</span><br><span class="line">truncate_prompt_tokens=<span class="literal">None</span>), guided_decoding=<span class="literal">None</span>, prompt_token_ids:</span><br><span class="line">[<span class="number">151644</span>, <span class="number">8948</span>, <span class="number">198</span>, <span class="number">2610</span>, <span class="number">525</span>, <span class="number">1207</span>, <span class="number">16948</span>, <span class="number">11</span>, <span class="number">3465</span>, <span class="number">553</span>, <span class="number">54364</span>,</span><br><span class="line"><span class="number">14817</span>, <span class="number">13</span>, <span class="number">1446</span>, <span class="number">525</span>, <span class="number">264</span>, <span class="number">10950</span>, <span class="number">17847</span>, <span class="number">13</span>, <span class="number">151645</span>, <span class="number">198</span>, <span class="number">151644</span>, <span class="number">872</span>,</span><br><span class="line"><span class="number">198</span>, <span class="number">100700</span>, <span class="number">105250</span>, <span class="number">16872</span>, <span class="number">104908</span>, <span class="number">104001</span>, <span class="number">9370</span>, <span class="number">105318</span>, <span class="number">151645</span>, <span class="number">198</span>,</span><br><span class="line"><span class="number">151644</span>, <span class="number">77091</span>, <span class="number">198</span>], lora_request: <span class="literal">None</span>, prompt_adapter_request: <span class="literal">None</span>.</span><br><span class="line"></span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">50</span>:<span class="number">17</span> async_llm_engine.py:<span class="number">207</span>] Added request chat-2eea5af7a0f9416abdd7b625863de374.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">50</span>:<span class="number">21</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.0</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">50</span>:<span class="number">31</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.0</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">50</span>:<span class="number">41</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.0</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">50</span>:<span class="number">51</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.0</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">51</span>:01 metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.0</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">51</span>:<span class="number">11</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.0</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">51</span>:<span class="number">19</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">4.6</span> tokens/s, Avg generation throughput: <span class="number">0.3</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">51</span>:<span class="number">24</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.8</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">51</span>:<span class="number">29</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.8</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">51</span>:<span class="number">35</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.5</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">51</span>:<span class="number">40</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.6</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br><span class="line">INFO <span class="number">11</span>-01 01:<span class="number">51</span>:<span class="number">46</span> metrics.py:<span class="number">363</span>] Avg prompt throughput: <span class="number">0.0</span> tokens/s, Avg generation throughput: <span class="number">0.7</span> tokens/s, Running: <span class="number">1</span> reqs, Swapped: <span class="number">0</span> reqs, Pending: <span class="number">0</span> reqs, GPU KV cache usage: <span class="number">0.0</span>%, CPU KV cache usage: <span class="number">0.0</span>%.</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°æœåŠ¡ç«¯å·²ç»æ¥æ”¶åˆ°è¯·æ±‚ï¼Œå¹¶å¼€å§‹é€æ­¥çš„è¿›è¡Œå¤„ç†ï¼Œå¤„ç†ç»“æŸåï¼Œå¯ä»¥çœ‹åˆ°æ¥å£è¿”å›ç»™å®¢æˆ·ç«¯çš„ç»“æœï¼Œè¿™é‡Œåœ¨å®¢æˆ·ç«¯è„šæœ¬ä¸­è¿›è¡Œæ‰“å°ï¼ˆè¿™é‡Œç­‰å¾…çš„æ—¶é—´æœ‰ç‚¹ä¹…ï¼Œå¦‚æœæ˜¯ 0.5B å°±å¾ˆå¿«ï¼‰ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">(ravllm) root@local:~/lmcode/<span class="number">25</span><span class="comment"># python requ.py</span></span><br><span class="line">Chat response: ChatCompletion</span><br><span class="line">(<span class="built_in">id</span>=<span class="string">&#x27;chat-2eea5af7a0f9416abdd7b625863de374&#x27;</span>, choices=[Choice</span><br><span class="line">(finish_reason=<span class="string">&#x27;stop&#x27;</span>, index=<span class="number">0</span>, logprobs=<span class="literal">None</span>,</span><br><span class="line">message=ChatCompletionMessage(content=<span class="string">&#x27;è‚¡å¸‚è¿è¡Œçš„åŸç†ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š</span></span><br><span class="line"><span class="string">\n\n1. ä¾›éœ€å…³ç³»ï¼šè‚¡å¸‚æ˜¯å•†å“å’ŒæœåŠ¡çš„ä»·æ ¼å†³å®šæœºåˆ¶ï¼Œè‚¡ç¥¨ä»·æ ¼ç”±å¸‚åœºä¸Šçš„ä¾›æ±‚å…³ç³»å†³å®šã€‚å½“</span></span><br><span class="line"><span class="string">å¸‚åœºä¸Šæœ‰æ›´å¤šçš„äººæƒ³è´­ä¹°è‚¡ç¥¨ï¼Œè€Œä¾›ä¸åº”æ±‚æ—¶ï¼Œè‚¡ç¥¨ä»·æ ¼ä¼šä¸Šæ¶¨ï¼›åä¹‹ï¼Œå½“å¸‚åœºä¸Šæœ‰æ›´å¤šçš„è‚¡ç¥¨</span></span><br><span class="line"><span class="string">ä¾›åº”ï¼Œè€Œéœ€æ±‚å°äºä¾›ç»™æ—¶ï¼Œè‚¡ç¥¨ä»·æ ¼ä¼šä¸‹è·Œã€‚\n\n2. åˆ©ç‡å˜åŠ¨ï¼šåˆ©ç‡çš„ä¸Šå‡é€šå¸¸ä¼šå¯¼è‡´è‚¡ç¥¨ä»·</span></span><br><span class="line"><span class="string">æ ¼ä¸‹é™ï¼Œå› ä¸ºé«˜åˆ©ç‡å¯èƒ½ä¼šé™ä½æŠ•èµ„è€…çš„é£é™©åå¥½ï¼Œå¯¼è‡´æŠ•èµ„è€…æ›´æ„¿æ„å°†èµ„é‡‘æŠ•èµ„äºå€ºåˆ¸ç­‰ä½é£</span></span><br><span class="line"><span class="string">é™©èµ„äº§ï¼Œè€Œä¸æ˜¯è‚¡ç¥¨ã€‚ç›¸åï¼Œå¦‚æœåˆ©ç‡ä¸‹é™ï¼Œè‚¡ç¥¨ä»·æ ¼é€šå¸¸ä¼šä¸Šæ¶¨ï¼Œå› ä¸ºæŠ•èµ„è€…å¯èƒ½æ›´æ„¿æ„å°†èµ„</span></span><br><span class="line"><span class="string">é‡‘æŠ•èµ„äºè‚¡ç¥¨ç­‰é«˜é£é™©èµ„äº§ã€‚\n\n3. å…¬å¸ä¸šç»©ï¼šå…¬å¸çš„ç›ˆåˆ©å’Œä¸šç»©æ˜¯å½±å“è‚¡ç¥¨ä»·æ ¼çš„é‡è¦å› </span></span><br><span class="line"><span class="string">ç´ ã€‚å½“ä¸€å®¶å…¬å¸ç›ˆåˆ©å¢é•¿æ—¶ï¼Œå…¶è‚¡ç¥¨ä»·æ ¼é€šå¸¸ä¼šä¸Šæ¶¨ï¼Œå› ä¸ºæŠ•èµ„è€…è®¤ä¸ºè¯¥å…¬å¸æœ‰æ›´é«˜çš„æœªæ¥æ”¶ç›Š</span></span><br><span class="line"><span class="string">æ½œåŠ›ã€‚ç›¸åï¼Œå¦‚æœå…¬å¸ä¸šç»©ä¸‹é™ï¼Œè‚¡ç¥¨ä»·æ ¼é€šå¸¸ä¼šä¸‹è·Œã€‚\n\n4. ç«äº‰ä¸å¹¶è´­ï¼šåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œ</span></span><br><span class="line"><span class="string">ç«äº‰å’Œå¹¶è´­ä¹Ÿä¼šå½±å“è‚¡å¸‚çš„è¿è¡Œã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸¤å®¶æˆ–å¤šå®¶å…¬å¸åˆå¹¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´å¸‚åœºä¸Šå¯ä¾›äº¤æ˜“</span></span><br><span class="line"><span class="string">çš„è‚¡ç¥¨æ•°é‡å‡å°‘ï¼Œä»è€Œæ¨é«˜è‚¡ç¥¨ä»·æ ¼ã€‚ç›¸åï¼Œå¦‚æœä¸€å®¶å…¬å¸è¢«å¦ä¸€å®¶æ”¶è´­ï¼Œå¯èƒ½ä¼šå¯¼è‡´è¯¥å…¬å¸è‚¡</span></span><br><span class="line"><span class="string">ç¥¨ä»·æ ¼ä¸‹è·Œï¼Œå› ä¸ºæŠ•èµ„è€…è®¤ä¸ºè¯¥å…¬å¸å¤±å»äº†éƒ¨åˆ†ä»·å€¼ã€‚\n\n5. æ”¿ç­–ä¸æ³•è§„ï¼šæ”¿åºœçš„æ”¿ç­–å’Œæ³•è§„</span></span><br><span class="line"><span class="string">ä¹Ÿå¯èƒ½å½±å“è‚¡å¸‚çš„è¿è¡Œã€‚ä¾‹å¦‚ï¼Œæ”¿åºœå¯èƒ½ä¼šå‡ºå°æ”¿ç­–æ¥åˆºæ¿€ç»æµå¢é•¿ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´è‚¡å¸‚ä¸Šæ¶¨ã€‚</span></span><br><span class="line"><span class="string">ç›¸åï¼Œå¦‚æœæ”¿åºœå‡ºå°äº†ç´§ç¼©æ€§çš„æ”¿ç­–ï¼Œå¯èƒ½ä¼šå¯¼è‡´è‚¡å¸‚ä¸‹è·Œã€‚\n\nä»¥ä¸Šå°±æ˜¯è‚¡å¸‚è¿è¡Œçš„åŸºæœ¬åŸ</span></span><br><span class="line"><span class="string">ç†ï¼Œå½“ç„¶ï¼Œè‚¡å¸‚è¿è¡Œå—åˆ°è®¸å¤šå…¶ä»–å› ç´ çš„å½±å“ï¼Œä¾‹å¦‚ç»æµçŠ¶å†µã€å›½é™…å½¢åŠ¿ã€æ”¿æ²»å±€åŠ¿ç­‰ç­‰ã€‚&#x27;</span>,</span><br><span class="line">refusal=<span class="literal">None</span>, role=<span class="string">&#x27;assistant&#x27;</span>, audio=<span class="literal">None</span>, function_call=<span class="literal">None</span>,</span><br><span class="line">tool_calls=[]), stop_reason=<span class="literal">None</span>)], created=<span class="number">1730425817</span>, model=<span class="string">&#x27;Qwen/</span></span><br><span class="line"><span class="string">Qwen2.5-1.5B-Instruct&#x27;</span>, <span class="built_in">object</span>=<span class="string">&#x27;chat.completion&#x27;</span>, service_tier=<span class="literal">None</span>,</span><br><span class="line">system_fingerprint=<span class="literal">None</span>, usage=CompletionUsage(completion_tokens=<span class="number">345</span>,</span><br><span class="line">prompt_tokens=<span class="number">36</span>, total_tokens=<span class="number">381</span>, completion_tokens_details=<span class="literal">None</span>,</span><br><span class="line">prompt_tokens_details=<span class="literal">None</span>), prompt_logprobs=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>åˆ°è¿™é‡Œå¯ä»¥ç®€å•çš„åº†ç¥ä¸‹äº†ï¼Œæ¯•ç«Ÿå·²ç»å¯ä»¥ä½¿ç”¨æœ¬åœ°éƒ¨ç½²è¿è¡Œçš„å¤§æ¨¡å‹äº†ã€‚</p><h4 id="4-3-é€šè¿‡-WebUI-è°ƒç”¨-api"><a href="#4-3-é€šè¿‡-WebUI-è°ƒç”¨-api" class="headerlink" title="4.3 é€šè¿‡ WebUI è°ƒç”¨ api"></a>4.3 é€šè¿‡ WebUI è°ƒç”¨ api</h4><p>è¿™é‡Œä½¿ç”¨äº† gradio</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install gradio</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">query_model</span>(<span class="params">prompt</span>):</span><br><span class="line">    api_url = <span class="string">&quot;http://127.0.0.1:8000/v1/chat/completions&quot;</span></span><br><span class="line">    headers = &#123;<span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;vLLM Client&quot;</span>&#125;</span><br><span class="line">    pload = &#123;</span><br><span class="line">        <span class="string">&quot;model&quot;</span>: <span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,</span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;],</span><br><span class="line">        <span class="string">&quot;max_tokens&quot;</span>: <span class="number">128</span>,</span><br><span class="line">        <span class="string">&quot;stream&quot;</span>: <span class="literal">True</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># å‘é€è¯·æ±‚ï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´ä¸º 1800 ç§’</span></span><br><span class="line">        response = requests.post(api_url, headers=headers, json=pload, stream=<span class="literal">True</span>, timeout=<span class="number">1800</span>)</span><br><span class="line"></span><br><span class="line">        result = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="comment"># å¤„ç†æµå¼è¿”å›çš„å“åº”</span></span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> response.iter_lines(chunk_size=<span class="number">8192</span>, decode_unicode=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">if</span> chunk:</span><br><span class="line">                chunk_str = chunk.decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(chunk_str)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># å»é™¤å¼€å¤´çš„ &quot;data: &quot; éƒ¨åˆ†ï¼Œç¡®ä¿æˆ‘ä»¬åªå¤„ç† JSON éƒ¨åˆ†</span></span><br><span class="line">                <span class="keyword">if</span> chunk_str.startswith(<span class="string">&quot;data: &quot;</span>):</span><br><span class="line">                    chunk_str = chunk_str[<span class="number">6</span>:].strip()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># ç¡®ä¿ä¸å¤„ç† keep-alive çš„å¿ƒè·³æ¶ˆæ¯</span></span><br><span class="line">                <span class="keyword">if</span> chunk_str == <span class="string">&quot;[DONE]&quot;</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># è§£æ JSON æ•°æ®</span></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    data = json.loads(chunk_str)</span><br><span class="line">                    <span class="comment"># ä»å“åº”ä¸­æå–å†…å®¹</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="string">&quot;choices&quot;</span> <span class="keyword">in</span> data:</span><br><span class="line">                        delta = data[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;delta&quot;</span>]</span><br><span class="line">                        <span class="keyword">if</span> <span class="string">&quot;content&quot;</span> <span class="keyword">in</span> delta:</span><br><span class="line">                            result += delta[<span class="string">&quot;content&quot;</span>]</span><br><span class="line">                <span class="keyword">except</span> json.JSONDecodeError:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;æ— æ³•è§£æçš„ JSON æ•°æ®ï¼š<span class="subst">&#123;chunk_str&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">except</span> requests.exceptions.Timeout:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•ã€‚&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;è¯·æ±‚å¤±è´¥ï¼š<span class="subst">&#123;e&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ„å»º Gradio UI</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_demo</span>():</span><br><span class="line">    <span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> demo:</span><br><span class="line">        gr.Markdown(<span class="string">&quot;# Qwen/Qwen2.5-1.5B-Instruct æ¨¡å‹äº¤äº’ç•Œé¢&quot;</span>)</span><br><span class="line">        prompt = gr.Textbox(label=<span class="string">&quot;è¾“å…¥æç¤º&quot;</span>, placeholder=<span class="string">&quot;è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æç¤º...&quot;</span>)</span><br><span class="line">        result = gr.Textbox(label=<span class="string">&quot;æ¨¡å‹å“åº”&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ä¿®æ­£ prompt.submit() è°ƒç”¨ï¼Œåªä¼ é€’ Gradio ç»„ä»¶</span></span><br><span class="line">        prompt.submit(query_model, inputs=prompt, outputs=result)</span><br><span class="line">    <span class="keyword">return</span> demo</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸»ç¨‹åºå…¥å£</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--host&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;0.0.0.0&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--port&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8001</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    demo = build_demo()</span><br><span class="line">    demo.queue().launch(server_name=args.host, server_port=args.port, share=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>ç„¶åè¿è¡ŒæœåŠ¡ï¼Œè¿™é‡Œæé†’ï¼Œä¸èƒ½åˆ›å»ºåˆ†äº«é“¾æ¥ï¼Œå¦‚æœæƒ³è¦åˆ›å»ºåˆ†äº«é“¾æ¥ï¼Œå°±æŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤è¿›è¡Œæ“ä½œå³å¯ã€‚</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(ravllm) root@local:~/lmcode/25# python ui.py</span><br><span class="line">* Running on local URL:  http://0.0.0.0:8001</span><br><span class="line"></span><br><span class="line">Could not create share link. Missing file: /root/miniconda3/envs/ravllm/lib/python3.10/site-packages/gradio/frpc_linux_amd64_v0.3.</span><br><span class="line"></span><br><span class="line">Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps:</span><br><span class="line"></span><br><span class="line">1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64</span><br><span class="line">2. Rename the downloaded file to: frpc_linux_amd64_v0.3</span><br><span class="line">3. Move the file to this location: /root/miniconda3/envs/ravllm/lib/python3.10/site-packages/gradio</span><br></pre></td></tr></table></figure><p>æŒ‰ç…§ä¸Šé¢çš„æ­¥éª¤ï¼Œä¸‹è½½ç§»åŠ¨ <code>frpc_linux_amd64</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">wget https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64</span><br><span class="line">mv frpc_linux_amd64 frpc_linux_amd64_v0.3</span><br><span class="line">mv frpc_linux_amd64_v0.3 /root/miniconda3/envs/ravllm/lib/python3.10/site-packages/gradio</span><br></pre></td></tr></table></figure><p>ç„¶åé‡æ–°å¯åŠ¨æœåŠ¡ï¼Œåœ¨æµè§ˆå™¨ä¸­è¿›è¡Œè®¿é—®ï¼Œå¯ä»¥çœ‹åˆ°ä»¥ä¸‹ç•Œé¢ï¼Œç„¶åå°±å¯ä»¥è¿›è¡Œäº¤äº’äº†ã€‚</p><p><img data-src="/posts/51728/webui.png" alt="webui.png"></p><p>è¿™é‡Œæˆªå–äº†å¤„ç†è¿‡ç¨‹ä¸­çš„ä¸€æ®µæ—¥å¿—ï¼Œå¯ä»¥çœ‹åˆ°è¯·æ±‚é€šè¿‡ <code>stream</code> çš„æ–¹å¼ï¼Œåƒç®¡é“ä¸­çš„æµæ°´ä¸€æ ·</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data: &#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;chat-f434de356a7d4e42b5ac89ea4d8d9b91&quot;</span>,<span class="string">&quot;object&quot;</span>:<span class="string">&quot;chat.completion.chunk&quot;</span>,<span class="string">&quot;created&quot;</span>:<span class="number">1730427228</span>,<span class="string">&quot;model&quot;</span>:<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,<span class="string">&quot;choices&quot;</span>:[&#123;<span class="string">&quot;index&quot;</span>:<span class="number">0</span>,<span class="string">&quot;delta&quot;</span>:&#123;<span class="string">&quot;role&quot;</span>:<span class="string">&quot;assistant&quot;</span>,<span class="string">&quot;content&quot;</span>:<span class="string">&quot;&quot;</span>&#125;,<span class="string">&quot;logprobs&quot;</span>:null,<span class="string">&quot;finish_reason&quot;</span>:null&#125;]&#125;</span><br><span class="line">data: &#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;chat-f434de356a7d4e42b5ac89ea4d8d9b91&quot;</span>,<span class="string">&quot;object&quot;</span>:<span class="string">&quot;chat.completion.chunk&quot;</span>,<span class="string">&quot;created&quot;</span>:<span class="number">1730427228</span>,<span class="string">&quot;model&quot;</span>:<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,<span class="string">&quot;choices&quot;</span>:[&#123;<span class="string">&quot;index&quot;</span>:<span class="number">0</span>,<span class="string">&quot;delta&quot;</span>:&#123;<span class="string">&quot;content&quot;</span>:<span class="string">&quot;èŠ¯ç‰‡&quot;</span>&#125;,<span class="string">&quot;logprobs&quot;</span>:null,<span class="string">&quot;finish_reason&quot;</span>:null&#125;]&#125;</span><br><span class="line">data: &#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;chat-f434de356a7d4e42b5ac89ea4d8d9b91&quot;</span>,<span class="string">&quot;object&quot;</span>:<span class="string">&quot;chat.completion.chunk&quot;</span>,<span class="string">&quot;created&quot;</span>:<span class="number">1730427228</span>,<span class="string">&quot;model&quot;</span>:<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,<span class="string">&quot;choices&quot;</span>:[&#123;<span class="string">&quot;index&quot;</span>:<span class="number">0</span>,<span class="string">&quot;delta&quot;</span>:&#123;<span class="string">&quot;content&quot;</span>:<span class="string">&quot;çš„&quot;</span>&#125;,<span class="string">&quot;logprobs&quot;</span>:null,<span class="string">&quot;finish_reason&quot;</span>:null&#125;]&#125;</span><br><span class="line">data: &#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;chat-f434de356a7d4e42b5ac89ea4d8d9b91&quot;</span>,<span class="string">&quot;object&quot;</span>:<span class="string">&quot;chat.completion.chunk&quot;</span>,<span class="string">&quot;created&quot;</span>:<span class="number">1730427228</span>,<span class="string">&quot;model&quot;</span>:<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,<span class="string">&quot;choices&quot;</span>:[&#123;<span class="string">&quot;index&quot;</span>:<span class="number">0</span>,<span class="string">&quot;delta&quot;</span>:&#123;<span class="string">&quot;content&quot;</span>:<span class="string">&quot;åˆ¶ä½œ&quot;</span>&#125;,<span class="string">&quot;logprobs&quot;</span>:null,<span class="string">&quot;finish_reason&quot;</span>:null&#125;]&#125;</span><br><span class="line">data: &#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;chat-f434de356a7d4e42b5ac89ea4d8d9b91&quot;</span>,<span class="string">&quot;object&quot;</span>:<span class="string">&quot;chat.completion.chunk&quot;</span>,<span class="string">&quot;created&quot;</span>:<span class="number">1730427228</span>,<span class="string">&quot;model&quot;</span>:<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,<span class="string">&quot;choices&quot;</span>:[&#123;<span class="string">&quot;index&quot;</span>:<span class="number">0</span>,<span class="string">&quot;delta&quot;</span>:&#123;<span class="string">&quot;content&quot;</span>:<span class="string">&quot;åŸç†&quot;</span>&#125;,<span class="string">&quot;logprobs&quot;</span>:null,<span class="string">&quot;finish_reason&quot;</span>:null&#125;]&#125;</span><br><span class="line">data: &#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;chat-f434de356a7d4e42b5ac89ea4d8d9b91&quot;</span>,<span class="string">&quot;object&quot;</span>:<span class="string">&quot;chat.completion.chunk&quot;</span>,<span class="string">&quot;created&quot;</span>:<span class="number">1730427228</span>,<span class="string">&quot;model&quot;</span>:<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,<span class="string">&quot;choices&quot;</span>:[&#123;<span class="string">&quot;index&quot;</span>:<span class="number">0</span>,<span class="string">&quot;delta&quot;</span>:&#123;<span class="string">&quot;content&quot;</span>:<span class="string">&quot;æ˜¯ä¸€é¡¹&quot;</span>&#125;,<span class="string">&quot;logprobs&quot;</span>:null,<span class="string">&quot;finish_reason&quot;</span>:null&#125;]&#125;</span><br><span class="line">data: &#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;chat-f434de356a7d4e42b5ac89ea4d8d9b91&quot;</span>,<span class="string">&quot;object&quot;</span>:<span class="string">&quot;chat.completion.chunk&quot;</span>,<span class="string">&quot;created&quot;</span>:<span class="number">1730427228</span>,<span class="string">&quot;model&quot;</span>:<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,<span class="string">&quot;choices&quot;</span>:[&#123;<span class="string">&quot;index&quot;</span>:<span class="number">0</span>,<span class="string">&quot;delta&quot;</span>:&#123;<span class="string">&quot;content&quot;</span>:<span class="string">&quot;éå¸¸&quot;</span>&#125;,<span class="string">&quot;logprobs&quot;</span>:null,<span class="string">&quot;finish_reason&quot;</span>:null&#125;]&#125;</span><br><span class="line">data: &#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;chat-f434de356a7d4e42b5ac89ea4d8d9b91&quot;</span>,<span class="string">&quot;object&quot;</span>:<span class="string">&quot;chat.completion.chunk&quot;</span>,<span class="string">&quot;created&quot;</span>:<span class="number">1730427228</span>,<span class="string">&quot;model&quot;</span>:<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,<span class="string">&quot;choices&quot;</span>:[&#123;<span class="string">&quot;index&quot;</span>:<span class="number">0</span>,<span class="string">&quot;delta&quot;</span>:&#123;<span class="string">&quot;content&quot;</span>:<span class="string">&quot;å¤æ‚&quot;</span>&#125;,<span class="string">&quot;logprobs&quot;</span>:null,<span class="string">&quot;finish_reason&quot;</span>:null&#125;]&#125;</span><br></pre></td></tr></table></figure><p>æœ¬åœ°éƒ¨ç½²çš„è¿™ä¸ªå¤§æ¨¡å‹ï¼Œè¿˜æœ‰äº›ç¼ºç‚¹ï¼Œä¾‹å¦‚ä¸èƒ½ç†è§£ä¸Šä¸‹æ–‡ã€‚<br>å¦‚æœéƒ¨ç½²æ˜¯åœ¨æœ‰ GPU æ˜¾å¡çš„æœåŠ¡å™¨ä¸Šï¼Œéƒ¨ç½²æ›´å¿«æ·ï¼Œæ¨¡å‹æ¨ç†æ›´å¿«ã€‚</p><h3 id="5-å‚è€ƒèµ„æ–™"><a href="#5-å‚è€ƒèµ„æ–™" class="headerlink" title="5 å‚è€ƒèµ„æ–™"></a>5 å‚è€ƒèµ„æ–™</h3><ul><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct/tree/main">https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct/tree/main</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://qwen.readthedocs.io/zh-cn/latest/deployment/vllm.html">https://qwen.readthedocs.io/zh-cn/latest/deployment/vllm.html</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/obullxl/p/18353447/NTopic2024081101">https://www.cnblogs.com/obullxl/p/18353447/NTopic2024081101</a></li></ul></div><footer class="post-footer"><div class="reward-container"><div>è¯·æˆ‘ä¸€æ¯å’–å•¡å§ï¼</div><button>èµèµ</button><div class="post-reward"><div><img src="/images/wechatpay.jpg" alt="é’é˜³åŠé›ª å¾®ä¿¡"> <span>å¾®ä¿¡</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>æœ¬æ–‡ä½œè€…ï¼š </strong>é’é˜³åŠé›ª</li><li class="post-copyright-link"><strong>æœ¬æ–‡é“¾æ¥ï¼š</strong> <a href="https://kycool.cn/posts/51728/" title="å¤§æ¨¡å‹ | CPU æ¨¡å¼éƒ¨ç½²è¿è¡Œ Qwen 2.5 å¤§æ¨¡å‹">https://kycool.cn/posts/51728/</a></li><li class="post-copyright-license"><strong>ç‰ˆæƒå£°æ˜ï¼š </strong>æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼</li></ul></div><div class="post-tags"><a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" rel="tag"># å¤§æ¨¡å‹</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/51727/" rel="prev" title="Django | ä¿¡å·ä½¿ç”¨æ€è€ƒ"><i class="fa fa-angle-left"></i> Django | ä¿¡å·ä½¿ç”¨æ€è€ƒ</a></div><div class="post-nav-item"></div></div></footer></article></div><div class="comments utterances-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener external nofollow noreferrer" target="_blank">ç²¤ ICP å¤‡ 15003910 å· -1</a></div><div class="copyright">&copy; 2015 â€“ <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">é’é˜³åŠé›ª</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span title="ç«™ç‚¹æ€»å­—æ•°">100k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="ç«™ç‚¹é˜…è¯»æ—¶é•¿">1:31</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="æ€»è®¿å®¢é‡"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="æ€»è®¿é—®é‡"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a> <a href="https://github.com/kycool" class="github-corner" title="åœ¨ GitHub ä¸Šå…³æ³¨æˆ‘" aria-label="åœ¨ GitHub ä¸Šå…³æ³¨æˆ‘" rel="noopener external nofollow noreferrer" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script src="/js/third-party/fancybox.js"></script><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"kycool/kycool.github.io","issue_term":"pathname","theme":"github-light"}</script><script src="/js/third-party/comments/utterances.js"></script></body></html>